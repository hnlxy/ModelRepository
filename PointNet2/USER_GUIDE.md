# PointNet2 Docker ä½¿ç”¨æŒ‡å—ä¸å·¥ä½œåŸç†

## ğŸ¯ æ•´ä½“æ¶æ„åŸç†

### 1. ç³»ç»Ÿæ¶æ„å›¾
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     ç”¨æˆ·ä½¿ç”¨å±‚                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  é…ç½®æ–‡ä»¶å±‚  â”‚  config_train.yml  â”‚  config_test.yml       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  è„šæœ¬æ‰§è¡Œå±‚  â”‚  train.sh  â”‚  test.sh  â”‚  inference.sh      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Dockerå®¹å™¨å±‚â”‚     harbor.yzai/.../ultralytics:v1_flask   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  ç®—æ³•æ‰§è¡Œå±‚  â”‚  PointNet2 è®­ç»ƒ/æµ‹è¯•/æ¨ç†ç®—æ³•               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  æ•°æ®å­˜å‚¨å±‚  â”‚  dataset/  â”‚  input/  â”‚  output/           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 2. å·¥ä½œæµç¨‹åŸç†
1. **é…ç½®è§£æ**: ä»YAMLé…ç½®æ–‡ä»¶è¯»å–å‚æ•°
2. **å®¹å™¨å¯åŠ¨**: æ ¹æ®é…ç½®å¯åŠ¨Dockerå®¹å™¨
3. **ç¯å¢ƒå‡†å¤‡**: å®¹å™¨å†…è‡ªåŠ¨é…ç½®Pythonç¯å¢ƒå’Œä¾èµ–
4. **æ•°æ®æ˜ å°„**: å®¿ä¸»æœºç›®å½•æ˜ å°„åˆ°å®¹å™¨å†…
5. **ç®—æ³•æ‰§è¡Œ**: åœ¨å®¹å™¨å†…æ‰§è¡ŒPointNet2ç®—æ³•
6. **ç»“æœè¾“å‡º**: ç»“æœä¿å­˜åˆ°æ˜ å°„çš„è¾“å‡ºç›®å½•

## ğŸ‘¥ ç”¨æˆ·ä½¿ç”¨åœºæ™¯

### åœºæ™¯1: å¼€å‘è€…ç¬¬ä¸€æ¬¡ä½¿ç”¨
```bash
# 1. è·å–é¡¹ç›®ä»£ç 
git clone <project-repo>
cd docker-PointNet2

# 2. å‡†å¤‡æ•°æ®é›†
mkdir -p dataset/data
# å°†ModelNet40æ•°æ®é›†æ”¾å…¥ dataset/data/ ç›®å½•

# 3. éªŒè¯ç¯å¢ƒé…ç½®
./validate_config.sh

# 4. æ„å»ºDockeré•œåƒï¼ˆä»…éœ€ä¸€æ¬¡ï¼‰
./build_docker.sh

# 5. å¼€å§‹è®­ç»ƒ
./run_docker.sh
# å®¹å™¨å¯åŠ¨åï¼Œåœ¨å®¹å™¨å†…æ‰§è¡Œï¼š
./train.sh
```

### åœºæ™¯2: å…¶ä»–ç”¨æˆ·ä½¿ç”¨å·²æ„å»ºçš„é•œåƒ
```bash
# 1. æ£€æŸ¥é•œåƒæ˜¯å¦å­˜åœ¨
docker images | grep harbor.yzai/cgf-ml-algorithm/ht/ultralytics

# 2. å¦‚æœé•œåƒä¸å­˜åœ¨ï¼Œæ‹‰å–é•œåƒ
docker pull harbor.yzai/cgf-ml-algorithm/ht/ultralytics:v1_flask

# 3. ç›´æ¥è¿è¡Œå®¹å™¨
./run_docker.sh
```

### åœºæ™¯3: æ‰¹é‡æ¨ç†ä½¿ç”¨
```bash
# 1. å‡†å¤‡æ¨ç†æ•°æ®
cp your_point_clouds.txt input/

# 2. å¯åŠ¨å®¹å™¨å¹¶æ‰§è¡Œæ¨ç†
./run_docker.sh
# å®¹å™¨å†…æ‰§è¡Œï¼š
./inference.sh

# 3. æŸ¥çœ‹ç»“æœ
cat output/results/prediction_results.txt
```

## ğŸ”§ æŠ€æœ¯åŸç†è¯¦è§£

### 1. é…ç½®ç®¡ç†åŸç†
```yaml
# config_train.yml å·¥ä½œåŸç†
dockerImage: harbor.yzai/cgf-ml-algorithm/ht/ultralytics:v1_flask  # æŒ‡å®šå®¹å™¨é•œåƒ
scriptPath: python algorithm/train_classification.py                 # æ‰§è¡Œè„šæœ¬è·¯å¾„
DATASET_ROOT_PATH: /workspace/dataset/data                          # å®¹å™¨å†…æ•°æ®è·¯å¾„
LOG_PATH: /workspace/output/log/classification                      # å®¹å™¨å†…æ—¥å¿—è·¯å¾„
```

**åŸç†è¯´æ˜**:
- é…ç½®æ–‡ä»¶ç»Ÿä¸€ç®¡ç†æ‰€æœ‰å‚æ•°ï¼Œé¿å…ç¡¬ç¼–ç 
- è·¯å¾„å‚æ•°ä½¿ç”¨å®¹å™¨å†…çš„æ ‡å‡†è·¯å¾„(`/workspace`)
- é€šè¿‡Volumeæ˜ å°„å®ç°å®¿ä¸»æœºä¸å®¹å™¨çš„æ•°æ®å…±äº«

### 2. Dockerå®¹å™¨åŒ–åŸç†
```dockerfile
# Dockerfile å…³é”®éƒ¨åˆ†åŸç†
FROM ultralytics/ultralytics:latest        # åŸºç¡€é•œåƒï¼šåŒ…å«CUDAå’ŒåŸºç¡€MLç¯å¢ƒ
WORKDIR /workspace                          # è®¾ç½®å·¥ä½œç›®å½•
ENV PYTHONPATH="${PYTHONPATH}:/workspace"  # é…ç½®Pythonè·¯å¾„
RUN pip install torch==2.0.0               # å®‰è£…ç‰¹å®šç‰ˆæœ¬ä¾èµ–
COPY . /workspace/                          # å¤åˆ¶ä»£ç åˆ°å®¹å™¨
```

**åŸç†è¯´æ˜**:
- åŸºäº`ultralytics`é•œåƒç¡®ä¿CUDAç¯å¢ƒä¸€è‡´æ€§
- é¢„å®‰è£…æ‰€æœ‰ä¾èµ–ï¼Œé¿å…è¿è¡Œæ—¶å®‰è£…é—®é¢˜
- æ ‡å‡†åŒ–å·¥ä½œç›®å½•å’Œç¯å¢ƒå˜é‡

### 3. æ•°æ®æµè½¬åŸç†
```bash
# æ•°æ®æµè½¬æ˜ å°„å…³ç³»
å®¿ä¸»æœºè·¯å¾„                     â†’    å®¹å™¨å†…è·¯å¾„
$(pwd)                        â†’    /workspace
$(pwd)/dataset               â†’    /workspace/dataset
$(pwd)/input                 â†’    /workspace/input
$(pwd)/output                â†’    /workspace/output
```

**æ•°æ®æµè½¬è¿‡ç¨‹**:
1. ç”¨æˆ·æ•°æ®æ”¾åœ¨å®¿ä¸»æœºç›®å½•
2. é€šè¿‡Volumeæ˜ å°„åˆ°å®¹å™¨å†…æ ‡å‡†è·¯å¾„
3. å®¹å™¨å†…ç®—æ³•è¯»å–æ ‡å‡†è·¯å¾„æ•°æ®
4. å¤„ç†ç»“æœå†™å…¥å®¹å™¨å†…è¾“å‡ºè·¯å¾„
5. é€šè¿‡æ˜ å°„åŒæ­¥åˆ°å®¿ä¸»æœºè¾“å‡ºç›®å½•

## ğŸš€ å®Œæ•´ä½¿ç”¨ç¤ºä¾‹

### ç¤ºä¾‹1: æ–°ç”¨æˆ·å®Œæ•´è®­ç»ƒæµç¨‹
```bash
# === ç¯å¢ƒå‡†å¤‡ ===
cd /path/to/docker-PointNet2
./validate_config.sh

# === æ„å»ºé•œåƒï¼ˆç®¡ç†å‘˜æ‰§è¡Œä¸€æ¬¡ï¼‰===
./build_docker.sh
# è¾“å‡º: ===== Dockeré•œåƒæ„å»ºæˆåŠŸ =====

# === ç”¨æˆ·è®­ç»ƒæµç¨‹ ===
# 1. å¯åŠ¨å®¹å™¨
./run_docker.sh
# è¿›å…¥å®¹å™¨åçš„æç¤ºç¬¦: root@container:/workspace#

# 2. å®¹å™¨å†…æ‰§è¡Œè®­ç»ƒ
./train.sh
# è¾“å‡º: Starting training...
#       Epoch 1/200: loss=2.345, acc=0.678
#       ...
#       Training completed!

# 3. å®¹å™¨å†…æ‰§è¡Œæµ‹è¯•
./test.sh
# è¾“å‡º: Starting evaluation...
#       Test accuracy: 0.892
#       Evaluation completed!

# 4. é€€å‡ºå®¹å™¨
exit

# 5. æŸ¥çœ‹ç»“æœï¼ˆåœ¨å®¿ä¸»æœºï¼‰
ls output/log/classification/
ls output/models/
```

### ç¤ºä¾‹2: é•œåƒåˆ†å‘ä½¿ç”¨
```bash
# === ç®¡ç†å‘˜ï¼šå¯¼å‡ºé•œåƒ ===
docker save harbor.yzai/cgf-ml-algorithm/ht/ultralytics:v1_flask > pointnet2_image.tar

# === å…¶ä»–ç”¨æˆ·ï¼šå¯¼å…¥å¹¶ä½¿ç”¨ ===
# 1. å¯¼å…¥é•œåƒ
docker load < pointnet2_image.tar

# 2. éªŒè¯é•œåƒ
docker images | grep ultralytics

# 3. ç›´æ¥ä½¿ç”¨
./run_docker.sh
```

## ğŸ“Š ç›‘æ§ä¸è°ƒè¯•

### 1. å®¹å™¨çŠ¶æ€ç›‘æ§
```bash
# æŸ¥çœ‹è¿è¡Œä¸­çš„å®¹å™¨
docker ps

# æŸ¥çœ‹å®¹å™¨èµ„æºä½¿ç”¨
docker stats pointnet2_container

# æŸ¥çœ‹å®¹å™¨æ—¥å¿—
docker logs pointnet2_container
```

### 2. è®­ç»ƒè¿‡ç¨‹ç›‘æ§
```bash
# å®æ—¶æŸ¥çœ‹è®­ç»ƒæ—¥å¿—
tail -f output/log/classification/train.log

# æŸ¥çœ‹GPUä½¿ç”¨æƒ…å†µ
nvidia-smi

# æŸ¥çœ‹è®­ç»ƒè¿›åº¦
ls -la output/models/  # æŸ¥çœ‹ä¿å­˜çš„æ¨¡å‹æ–‡ä»¶
```

## âš ï¸ å¸¸è§é—®é¢˜ä¸è§£å†³æ–¹æ¡ˆ

### é—®é¢˜1: é•œåƒæ„å»ºå¤±è´¥
```bash
# åŸå› ï¼šDockeræœåŠ¡æœªå¯åŠ¨
sudo systemctl start docker

# åŸå› ï¼šæƒé™ä¸è¶³
sudo usermod -aG docker $USER
```

### é—®é¢˜2: å®¹å™¨æ— æ³•è®¿é—®GPU
```bash
# æ£€æŸ¥nvidia-docker
nvidia-smi
docker run --gpus all nvidia/cuda:11.0-base nvidia-smi
```

### é—®é¢˜3: æ•°æ®è·¯å¾„é—®é¢˜
```bash
# æ£€æŸ¥è·¯å¾„æ˜ å°„
docker run -it --rm -v $(pwd):/workspace ubuntu ls -la /workspace
```

## ğŸ¯ æœ€ä½³å®è·µå»ºè®®

### 1. å›¢é˜Ÿåä½œæœ€ä½³å®è·µ
- **ç»Ÿä¸€ç¯å¢ƒ**: æ‰€æœ‰æˆå‘˜ä½¿ç”¨ç›¸åŒçš„Dockeré•œåƒ
- **é…ç½®ç®¡ç†**: é€šè¿‡Gitç®¡ç†é…ç½®æ–‡ä»¶ç‰ˆæœ¬
- **æ•°æ®æ ‡å‡†**: ç»Ÿä¸€æ•°æ®é›†ç›®å½•ç»“æ„
- **ç»“æœå…±äº«**: ä½¿ç”¨å…±äº«å­˜å‚¨ä¿å­˜è®­ç»ƒç»“æœ

### 2. ç”Ÿäº§ç¯å¢ƒéƒ¨ç½²
- **é•œåƒä»“åº“**: å°†é•œåƒæ¨é€åˆ°ç§æœ‰ä»“åº“
- **è‡ªåŠ¨åŒ–éƒ¨ç½²**: ä½¿ç”¨CI/CDç®¡é“è‡ªåŠ¨æ„å»ºå’Œéƒ¨ç½²
- **èµ„æºç®¡ç†**: é…ç½®GPUèµ„æºé™åˆ¶å’Œè°ƒåº¦
- **ç›‘æ§å‘Šè­¦**: é›†æˆç›‘æ§ç³»ç»Ÿè¿½è¸ªè®­ç»ƒçŠ¶æ€

### 3. å¼€å‘è°ƒè¯•æŠ€å·§
- **äº¤äº’å¼è°ƒè¯•**: ä½¿ç”¨`docker exec -it`è¿›å…¥è¿è¡Œä¸­çš„å®¹å™¨
- **ä»£ç çƒ­æ›´æ–°**: é€šè¿‡Volumeæ˜ å°„å®ç°ä»£ç å®æ—¶æ›´æ–°
- **æ—¥å¿—åˆ†æ**: ä½¿ç”¨ELKæ ˆåˆ†æè®­ç»ƒæ—¥å¿—
- **æ€§èƒ½ä¼˜åŒ–**: ç›‘æ§GPUåˆ©ç”¨ç‡å’Œå†…å­˜ä½¿ç”¨

è¿™å¥—DockeråŒ–çš„PointNet2ç³»ç»Ÿé€šè¿‡æ ‡å‡†åŒ–çš„é…ç½®ç®¡ç†ã€å®¹å™¨åŒ–éƒ¨ç½²å’Œè‡ªåŠ¨åŒ–è„šæœ¬ï¼Œå®ç°äº†ç®—æ³•çš„å¿«é€Ÿéƒ¨ç½²å’Œå›¢é˜Ÿåä½œï¼Œå¤§å¤§é™ä½äº†ç¯å¢ƒé…ç½®çš„å¤æ‚æ€§å’Œé”™è¯¯ç‡ã€‚
